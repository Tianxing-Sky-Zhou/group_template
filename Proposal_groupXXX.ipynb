{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
    "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training an unsupervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "\n",
    "- The project must include some elements of unsupervised learning, but you are welcome to include some supervised or other learning approaches as well.\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Tianxing Zhou\n",
    "- Samar Marwah\n",
    "- Shaoming Chen\n",
    "- Tiashi Hu\n",
    "- Yueshan Huang\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents and how they are measured\n",
    "- what you will be doing with the data\n",
    "- how performance/success will be measured\n",
    "\n",
    "Classifying galaxies, stars, and quasars has always been a pivotal problem in astrophysics research. The goal of the project is to distinguish astronomical objects such as galaxies, stars, or quasars(QSO). To effectively classify these objects, a precise measurement of photometry is required. We will use the Sloan Digital Sky Survey Data Release 18 (SDSS-DR18), which contains photometry information from ultraviolet to near-infrared. Our objective is to develop a machine-learning framework that employs dimensionality reduction techniques such as Principal Component Analysis (PCA) to distill the high-dimensional data inherent to astronomical observations. Subsequently, we apply the clustering algorithm such as K-means clustering algorithm to classify the observed celestial bodies into distinct categories: galaxies, stars, and quasars. The performance of our classification model will be evaluated based on the Adjusted Random Score. With the advent of next-generation telescopes such as the James Webb Space Telescope, the field of astronomy is in critical need of robust, automated classification methods capable of handling large and complex datasets. By using machine-learning techniques, we can create a model capable of categorization astronomical objects, facilitating deeper insights into the cosmos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "Exploring the depths of the cosmos and deciphering its mysteries lies at the heart of astrophysics. Central to this quest is the Sloan Digital Sky Survey (SDSS)<a name=\"Almeidanote\"></a>[<sup>[1]</sup>](#Almeida), a treasure trove of celestial data capturing the essence of stars, galaxies, and enigmatic quasars. This expansive dataset serves as a beacon for astronomers, offering profound insights into the universe's tapestry. With 100,000 observations, this dataset offers a comprehensive view of the universe's constituents. Spectral characteristics, such as right ascension, declination, and photometric filter measurements across multiple wavelengths, are essential for understanding the nature of these celestial bodies. Additionally, redshift values <a name=\"Zehavinote\"></a>[<sup>[2]</sup>](#Zehavi) derived from observed wavelength shifts provide crucial insights into their distances and velocities. Previous research utilizing SDSS data has significantly advanced our knowledge of cosmology, stellar evolution, and galaxy formation. Leveraging machine learning approaches<a name=\"Jinnote\"></a>[<sup>[3]</sup>](#Jin) on this dataset enables automated classification, contributing to ongoing efforts in understanding the cosmos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once).\n",
    "\n",
    "- In the context of modern astronomy, the handling and analysis of large and high-dimensional datasets of celestial objects are constrained by inherent data interpretation and object classification complexities. Data obtained from sky surveys, like that encompassing a mixture of stars, galaxies, and quasities, generate properties for celestial objects across several spectral bands. A critical condition is the ever-increasing rate of this data collection that outpaces the development of both computational training constraints and the granulation of the named cluster classes. Additionally, analyzing high-dimensional spectral and spatial features creates an encumbrance for creating intelligible 2D or 3D photometric representation models that can capture the underlying object type.Consequently, we intend to solve the problem statement by: Cluster new classes of astronomical objects and refine existing classifications based on their features and Visualize high-dimensional data in 2D or 3D to identify patterns or groupings that are not apparent in higher-dimensional space.with the help of K-Means, Hierarchical Clustering and PCA (potential solution). \n",
    "- Quantifiable: The variables in the dataset we used are numeric, hence we can utilize the mathematical expression to compute the variables and put them into K-means, Hierarchical Clustering even including PCA matrix calculations.\n",
    "- Measurable: Adjusted Rand Score in K-Means and Hierarchical Clustering. Range: -1 to 1, where 1 indicates perfect agreement between clusterings. Reconstruction Error can be measured with PCA.\n",
    "- Replicable: The dataset is replicable as the stars are very abundant in the universe and it is plausible to take another galaxy and find the star-data and reproduce the result. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "You should have a strong idea of what dataset(s) will be used to accomplish this project. \n",
    "\n",
    "If you know what (some) of the data you will use, please give the following information for each dataset:\n",
    "- link/reference to obtain it\n",
    "- description of the size of the dataset (# of variables, # of observations)\n",
    "- what an observation consists of\n",
    "- what some critical variables are, how they are represented\n",
    "- any special handling, transformations, cleaning, etc will be needed\n",
    "\n",
    "If you don't yet know what your dataset(s) will be, you should describe what you desire in terms of the above bullets.\n",
    "\n",
    "- Link and reference: https://www.kaggle.com/datasets/diraf0/sloan-digital-sky-survey-dr18/data\n",
    "- Description: This dataset contains data on celestial objects from the Sloan Digital Sky Survey, which comprises 100,000 observations with 42 features.\n",
    "- Observation: \n",
    "  - Objid, Specobjid - Object Identifiers\n",
    "  - Ra: right ascension is used to pinpoint locations of objects in the sky. \n",
    "  - Dec: declination is another coordinate used to pinpoint locations of objects in the sky, it measures the angular distance of an object north or south of the celestial equator.\n",
    "  - Redshift: a measure of how much the wavelength of the light from an object has been stretched due to the expansion of the universe, indicating the distance of velocity of celestial objects moving away from us.\n",
    "  - u, g, r, i, and z (Photometric Magnitudes): \n",
    "      - u (ultraviolet): Captures light in the ultraviolet spectrum.\n",
    "      - g (green): Measures light in the green part of the visible spectrum.\n",
    "      - r (red): Measures light in the red part of the visible spectrum.\n",
    "      - i (infrared): Detects light in the near-infrared spectrum.\n",
    "      - z (near-infrared): Captures light in the near-infrared spectrum, but at longer wavelengths than 'i'.\n",
    "  - run (Run Number): specific observational run which data was collected\n",
    "  - rerun (Rerun Number): specific observational run which data was recollected\n",
    "  - camcol (Camera Column): the column of the camera detector array that captured the image.\n",
    "  - field (Field Number): an identifier for a specific region of the sky observed during the survey.\n",
    "- Critical variables: Photometric Magnitudes\n",
    "  - Measures the brightness of celestial objects in specific wavelength bands and each band captures light from a different part of the electromagnetic spectrum. \n",
    "  - The magnitudes are presented as decimal numbers representing a ratio of brightness to a base celestial object (E.g. Vega). These magnitudes are measured on a logarithmic scale, defined such that a difference of 5 magnitudes corresponds to a factor of 100 in brightness. In other words, a decrease in magnitude by 1 unit represents an increase in brightness (and thus energy) by a factor of approximately 2.512. We can also calculate the magnitude using this formula: $m = -2.5 \\log_{10} \\left( \\frac{F}{F_0} \\right)$\n",
    "- Data cleaning:\n",
    "  - We will remove unimportant features such as Object Identifiers, run and rerun numbers, and field numbers, etc. Additionally, we will conduct standard tests to check for outliers, missing values, and duplicate entries. If necessary, we will also attempt to normalize the magnitude values to ensure they are on a comparable scale. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Why might your solution work? Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. \n",
    "\n",
    "Our solution will integrate PCA for dimensionality reduction, followed by the application of K-Means and Hierarchical Clustering algorithms for pattern recognition and classification. PCA will be employed to transform the high-dimensional data into a lower-dimensional subspace so that we may preserve variance as much as possible. K-Means clustering will serve to partition the dataset into distinct groups, based on feature similarity. Hierarchical clustering will complement this process by providing a dendrogram, offering insights into the hierarchical structure of the data and allowing for identification of nested clusters. This dual-clustering approach aims to maximize the interpretability of the data’s structure in reduced dimensions and reveal subtle classifications that may not be discernible in original high-dimensional space. The efficacy of this solution will be gauged by the clarity of the clusters formed and their alignment with known astrophysical phenomena. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms).\n",
    "\n",
    "\n",
    "The evaluation metrics we used primarily is Adjusted Random Score for K-means and Hierarchical Clustering and Reconstruction error for PCA. Adjusted Random Score Measures the similarity between two clusterings, including the true cluster assignments and those produced by the algorithm, adjusting for chance. Its range is -1 to 1, where 1 indicates perfect agreement between clusterings. \n",
    "$$\n",
    "\\text{Adjusted Random Score} = \\frac{\\sum_{ij} \\binom{n_{ij}}{2} - \\left[\\sum_i \\binom{a_i}{2} \\sum_j \\binom{b_j}{2}\\right] / \\binom{n}{2}}{\\frac{1}{2} \\left[\\sum_i \\binom{a_i}{2} + \\sum_j \\binom{b_j}{2}\\right] - \\left[\\sum_i \\binom{a_i}{2} \\sum_j \\binom{b_j}{2}\\right] / \\binom{n}{2}}\n",
    "$$\n",
    "\n",
    "- $n_{ij}$ is the number of objects in both clusters $i$ and $j$.\n",
    "- $a_i$ is the number of objects in cluster $i$.\n",
    "- $b_j$ is the number of objects in cluster $j$.\n",
    "- $n$ is the total number of objects.\n",
    "\n",
    "\n",
    "Also, After reducing the dimensions, reconstructing the original data from the reduced dimensions will not be perfect. The reconstruction error measures the difference between the original data and the reconstructed data from the principal components. Lower reconstruction errors indicate that the principal components retain more information from the original dataset. $\\text{Reconstruction Error} = \\|X - \\hat{X}\\|_F$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination. Get creative!\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org\n",
    "\n",
    "In our use of the Sloan Digital Sky Survey (SDSS) dataset for machine learning in astronomy, we encounter ethical and privacy considerations. While astronomical data typically lacks personal identifiers, the risk of inadvertently exposing sensitive information increases when datasets are combined. Additionally, biases inherent in the data could skew model predictions, potentially perpetuating inaccuracies in astronomical research. To address these concerns, we prioritize data privacy and bias mitigation, employing rigorous evaluations and transparent communication of findings. Leveraging tools like Deon (https://deon.drivendata.org), we aim to ensure responsible and ethical use of the SDSS dataset in our astronomical research endeavors through machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "\n",
    "* *We expect to communicate and evaluate our progress several times a week* \n",
    "* *We will relay information through our discord group and github*\n",
    "* *We expect to handle and disputes civilly, and to distribute work evenly and fairly*\n",
    "* *We will make a schedule of when we want certain aspects of the project done and adhere to it*\n",
    "* *We will make sure everyone's opinions are heard*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/20  |  4 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 2/27  |  4 PM |  Have data set wrangled(all) | Discuss our roles and divy up roles for remainder of project | \n",
    "| 3/6  | 4 PM  | Edit and finalize abstract, background as well as EDA (all, each assigned a portion)  | Discuss Analysis Plan   |\n",
    "| 3/13  | 4 PM | Data analysis done (methods split up amongst group) | Review/Edit Analysis as well as finalize are portions of the project   |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "\n",
    "- <a name=\"Almeidanote\"></a>1.[^](#Almeida): Andrés Almeida et al. \"The Eighteenth Data Release of the Sloan Digital Sky Surveys: Targeting and First Spectra from SDSS-V”, 2023 ApJS 267 44. https://iopscience.iop.org/article/10.3847/1538-4365/acda98.\n",
    "- <a name=\"Zehavinote\"></a>2.[^](#Zehavi): Idit Zehavi et al. \"GALAXY CLUSTERING IN THE COMPLETED SDSS REDSHIFT SURVEY: THE DEPENDENCE ON COLOR AND LUMINOSITY\", 2011 ApJ 736 59.https://iopscience.iop.org/article/10.1088/0004-637X/736/1/59\\\n",
    "- <a name=\"Jinnote\"></a>3.[^](#Jin):Jin, X., Han, J. (2011). K-Means Clustering. In: Sammut, C., Webb, G.I. (eds) Encyclopedia of Machine Learning. Springer, Boston, MA. https://doi.org/10.1007/978-0-387-30164-8_425\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
